{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2690a00c-1b55-4664-9b56-e2a042b1f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook, load_workbook\n",
    "from docx import Document\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827db189-7254-4d82-adef-604849b148eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'input_files_v3/Annotated_Papers'\n",
    "folder_names = os.listdir(root_folder + '/')\n",
    "\n",
    "root_save_folder = 'output_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b310ed3-ab19-4150-abf0-38645e53b815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files - 192\n"
     ]
    }
   ],
   "source": [
    "# creating a set of all file IDs\n",
    "id_locations = dict()\n",
    "# for folder in folder_names:\n",
    "# grader_folders = os.listdir(root_folder + '/' + folder + '/')\n",
    "for grader_folder in folder_names:\n",
    "    file_names = os.listdir(root_folder + '/' + grader_folder + '/')\n",
    "    for file in file_names:\n",
    "        name, ext = os.path.splitext(file)\n",
    "        if ext != '.docx':\n",
    "            print('/' + grader_folder + '/' + file)\n",
    "            continue\n",
    "        file_id = file.split('-')[0]\n",
    "        if file_id in id_locations:\n",
    "            id_locations[file_id].append(root_folder + '/' + grader_folder + '/' + file)\n",
    "        else:\n",
    "            id_locations[file_id] = [root_folder + '/' + grader_folder + '/' + file]\n",
    "\n",
    "print(f'Total Files - {len(id_locations)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d4dbba4-a2a2-4c7c-9603-579372cd8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapping = {\"AC\" : \"Andrew Chapman\",\n",
    "                \"AN\" : \"Ashlan Stewart\",\n",
    "                \"BA\" : \"Beatriz Acosta-Tsvilin\",\n",
    "                \"JM\" : \"Jasmine McCray\",\n",
    "                \"JD\" : \"Jessica Dobbs\",\n",
    "                \"MK\" : \"Maliha Kabir\",\n",
    "                \"MB\" : \"Marina Banchetti\",\n",
    "                \"NC\" : \"Nikki Chasteen\",\n",
    "                \"SN\" : \"Sarah Nielsen\"}\n",
    "\n",
    "id_mapping = {\"AC\" : 'C',\n",
    "               \"AN\" : 'D',\n",
    "               \"BA\" : 'E',\n",
    "               \"JM\" : 'F',\n",
    "               \"JD\" : 'G',\n",
    "               \"MK\" : 'H',\n",
    "               \"MB\" : 'I',\n",
    "               \"NC\" : 'J',\n",
    "               \"SN\" : 'K'}\n",
    "\n",
    "color_2_num = {\n",
    "    'YELLOW' : 7,\n",
    "    'BRIGHT_GREEN' : 4,\n",
    "    'DARK_YELLOW' : 14,\n",
    "    'RED' : 6,\n",
    "    'TURQUOISE' : 3,\n",
    "    'GRAY' : 16\n",
    "}\n",
    "\n",
    "color_2_label = {\n",
    "    'YELLOW' : \"Thesis\",\n",
    "    'BRIGHT_GREEN' : \"Organizational Framework\",\n",
    "    'DARK_YELLOW' : \"Rhetorical Structure - Focus\",\n",
    "    'RED' : \"Evidence\",\n",
    "    'TURQUOISE' : \"Reasoning\",\n",
    "    'GRAY' : \"Rhetorical Structure - Progression\"\n",
    "}\n",
    "\n",
    "cust_punct = '!@#$%^&*()-=_+`~[]\\{}|;:,./<>?' + '\"' + \"'\" + '“”„‟‘’‚‛' + '\\n' + ' ' # + ' '\n",
    "alpha_num = '[^a-zA-Z0-9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ef2ed33-343f-444b-afbb-be9e604d23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = dict()\n",
    "para_number = 0\n",
    "for file_id in id_locations.keys():    # ['09516']:\n",
    "    total_words = []\n",
    "    all_words = []\n",
    "    rater_names = []\n",
    "    for file_location in id_locations[file_id]:\n",
    "        rater = file_location.split('/')[2].split()[1]\n",
    "        # print(file_location)\n",
    "        doc = Document(file_location)\n",
    "        total_string = []\n",
    "        prev, curr = 'normal_text', 'normal_text'\n",
    "        for paragraph in doc.paragraphs:\n",
    "            runs = paragraph.runs\n",
    "            n_runs = len(runs)\n",
    "            temp_string = \"\"\n",
    "            for i in range(n_runs):\n",
    "                if runs[i].font.highlight_color:\n",
    "                    # is_highlighted = is_highlighted or True   # if there is any run with a highlight, make is_highlighted = True\n",
    "                    if runs[i].font.highlight_color == color_2_num['YELLOW']:\n",
    "                        curr = color_2_label['YELLOW']\n",
    "                    elif runs[i].font.highlight_color == color_2_num['BRIGHT_GREEN']:\n",
    "                        curr = color_2_label['BRIGHT_GREEN']\n",
    "                    elif runs[i].font.highlight_color == color_2_num['DARK_YELLOW']:\n",
    "                        curr = color_2_label['DARK_YELLOW']\n",
    "                    elif runs[i].font.highlight_color == color_2_num['RED']:\n",
    "                        curr = color_2_label['RED']\n",
    "                    elif runs[i].font.highlight_color == color_2_num['TURQUOISE']:\n",
    "                        curr = color_2_label['TURQUOISE']\n",
    "                    elif runs[i].font.highlight_color == color_2_num['GRAY']:\n",
    "                        curr = color_2_label['GRAY']\n",
    "                else:\n",
    "                    curr = 'normal_text'\n",
    "                    \n",
    "                if curr == prev:\n",
    "                    temp_string += re.sub(alpha_num, ' ', runs[i].text)\n",
    "                else:\n",
    "                    total_string += [[i, prev, para_number] for i in temp_string.strip().split() if i.strip()]\n",
    "                    temp_string = re.sub(alpha_num, ' ', runs[i].text)\n",
    "                    \n",
    "                if i == n_runs - 1:\n",
    "                    total_string += [[i, curr, para_number] for i in temp_string.strip().split() if i.strip()]\n",
    "\n",
    "                prev = curr\n",
    "            para_number += 1\n",
    "        total_words.append(len(total_string))\n",
    "        all_words.append(total_string)\n",
    "        rater_names.append(rater)\n",
    "    \n",
    "    new_data[file_id] = all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77c094c-41f1-44f4-9efe-f3fe9f74894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same(l1, l2):\n",
    "    ret = True\n",
    "    n1, n2 = len(l1), len(l2)\n",
    "    if n1 != n2:\n",
    "        ret = False\n",
    "    else:\n",
    "        for i in range(n1):\n",
    "            if l1[i][0] != l2[i][0]:\n",
    "                ret = False\n",
    "                break\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f930d445-c629-4849-8c1e-e9d159055c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_same(l1, l2):\n",
    "    temp1, temp2 = copy.deepcopy(l1), copy.deepcopy(l2)\n",
    "    try:\n",
    "        i = 0\n",
    "        while not is_same(l1, l2):\n",
    "            if l1[i][0] != l2[i][0]:\n",
    "                if l1[i][0]+l1[i+1][0] == l2[i][0]:\n",
    "                    l1[i][0] = l1[i][0]+l1[i+1][0]\n",
    "                    l1[i][1] = l1[i+1][1]\n",
    "                    l1.pop(i+1)\n",
    "                elif l1[i][0] == l2[i][0]+l2[i+1][0]:\n",
    "                    l2[i][0] = l2[i][0]+l2[i+1][0]\n",
    "                    l2[i][1] = l2[i+1][1]\n",
    "                    l2.pop(i+1)\n",
    "            i = i + 1\n",
    "        success = True\n",
    "    except:\n",
    "        l1, l2 = temp1, temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622895b9-cf7f-4b5a-b9f1-09c5a9254904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_frequency(numbers):\n",
    "    from collections import Counter\n",
    "\n",
    "    if not numbers:\n",
    "        return -1\n",
    "    \n",
    "    # Handle the case where there is only one element in the list or all elements are the same\n",
    "    if len(numbers) == 1 or len(set(numbers)) == 1:\n",
    "        return numbers[0]\n",
    "    \n",
    "    # Count the frequency of each number in the list\n",
    "    frequency = Counter(numbers)\n",
    "    \n",
    "    # Get the frequencies in a list\n",
    "    frequency_values = list(frequency.values())\n",
    "    \n",
    "    # Check if all frequencies are the same\n",
    "    if all(frequency_value == frequency_values[0] for frequency_value in frequency_values):\n",
    "        return -1\n",
    "    \n",
    "    # Find the number with the maximum frequency\n",
    "    max_frequency = max(frequency_values)\n",
    "    \n",
    "    # Get the number corresponding to the maximum frequency\n",
    "    for number, freq in frequency.items():\n",
    "        if freq == max_frequency:\n",
    "            return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7dcb23-2364-4bc6-8e32-a0f92078dd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency([1,1,1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5dae566-00b2-4737-9929-a2051a3ace39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 16 268\n",
      "521 8 74\n",
      "521 8 74\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    all_same = 0\n",
    "    not_same = 0\n",
    "    diff_len = 0\n",
    "    \n",
    "    for file_id in new_data.keys():\n",
    "        words_list = new_data[file_id]\n",
    "        if len(words_list) > 1:\n",
    "            n = len(words_list)\n",
    "            for i in range(0, n-1):\n",
    "                for j in range(i+1, n):\n",
    "                    words_1 = words_list[i]\n",
    "                    words_2 = words_list[j]\n",
    "                    \n",
    "                    if len(words_1) != len(words_2):\n",
    "                        diff_len += 1\n",
    "                        make_same(words_1, words_2)\n",
    "                    else:\n",
    "                        z = 0\n",
    "                        while z < len(words_1) and (words_1[z][0] == words_2[z][0]):\n",
    "                            z = z + 1\n",
    "                        if z == len(words_1):\n",
    "                            all_same += 1\n",
    "                        else:\n",
    "                            not_same += 1\n",
    "                            make_same(words_1, words_2)\n",
    "    \n",
    "    print(all_same, not_same, diff_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "646ad72b-c7e8-4365-8da1-56f86930be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = dict()\n",
    "for file_id in new_data.keys():\n",
    "    len_count = []\n",
    "    words_lists = new_data[file_id]\n",
    "    for words_list in words_lists:\n",
    "        len_count.append(len(words_list))\n",
    "\n",
    "    common_len = max_frequency(len_count)\n",
    "    common_len_words = []\n",
    "\n",
    "    for words_list in words_lists:\n",
    "        if len(words_list) == common_len:\n",
    "            common_len_words.append(words_list)\n",
    "\n",
    "    if len(common_len_words) == 1:\n",
    "        final_data[file_id] = common_len_words[0]\n",
    "    else:\n",
    "        n = len(common_len_words)\n",
    "        words = []\n",
    "        for i in range(common_len):\n",
    "            word = common_len_words[0][i][0]\n",
    "            para_number = common_len_words[0][i][2]\n",
    "            word_lables = []\n",
    "            for j in range(n):\n",
    "                # print(i,j)\n",
    "                word_lables.append(common_len_words[j][i][1])\n",
    "                freq_label = max_frequency(word_lables)\n",
    "            if freq_label == -1:\n",
    "                freq_label = word_lables[0]\n",
    "            words.append([word, freq_label, para_number])\n",
    "        final_data[file_id] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f421acd9-d0bf-4854-ae75-d0024c40222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "temp = []\n",
    "for file_id in final_data.keys():\n",
    "    asas = set()\n",
    "    for aa in final_data[file_id]:\n",
    "        asas.add(aa[1])\n",
    "    if len(asas) >= 2:\n",
    "        for aa in final_data[file_id]:\n",
    "            temp.append([file_id, aa[0] + \" \", aa[1], aa[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7ca6b76-1827-43b4-a745-c21c1448eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(temp, columns=['file_id', 'text', 'label', 'para_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "078c4005-5149-4a1a-a57b-40fcf78f6581",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_key = (df['label'] != df['label'].shift(1)).cumsum()\n",
    "final_df = df.groupby(['file_id', 'para_number', 'label'], as_index=False)['text'].sum().drop(columns=['para_number'])\n",
    " #.groupby(group_key, as_index=False).agg({'file_id': 'first', 'para_number': 'first', 'text': 'sum', 'label': 'first'}).drop(columns=['para_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91d16543-f1c9-458f-8ed3-83dff05fe3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09474</td>\n",
       "      <td>normal_text</td>\n",
       "      <td>Full Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09474</td>\n",
       "      <td>normal_text</td>\n",
       "      <td>Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09474</td>\n",
       "      <td>normal_text</td>\n",
       "      <td>ENC1101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09474</td>\n",
       "      <td>normal_text</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09474</td>\n",
       "      <td>normal_text</td>\n",
       "      <td>Overdosing on Stereotypes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_id        label                        text\n",
       "0   09474  normal_text                  Full Name \n",
       "1   09474  normal_text                 Instructor \n",
       "2   09474  normal_text                    ENC1101 \n",
       "3   09474  normal_text                       Date \n",
       "4   09474  normal_text  Overdosing on Stereotypes "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0acbfde0-280f-465d-8710-85466f16656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel(root_save_folder + '/' +'consistent_reannotation.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_ra",
   "language": "python",
   "name": "nlp_ra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
