{"cells":[{"cell_type":"code","source":["from IPython.display import HTML, display\n","\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)"],"metadata":{"id":"StFwXYna_XVK","executionInfo":{"status":"ok","timestamp":1747021520910,"user_tz":240,"elapsed":4,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install transformers==4.28.1 datasets evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"XuKsyeIRPSDQ","executionInfo":{"status":"ok","timestamp":1747021532539,"user_tz":240,"elapsed":11627,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"b3626f7d-7ccc-472c-e876-28f75ab7bb98"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.28.1\n","  Downloading transformers-4.28.1-py3-none-any.whl.metadata (109 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/110.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n","Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.1) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.1) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.1) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.1) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.1) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.1) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.1) (2.32.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.1)\n","  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.28.1) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.28.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.28.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.28.1) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.28.1) (2025.4.26)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, xxhash, fsspec, dill, multiprocess, transformers, datasets, evaluate\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.1\n","    Uninstalling tokenizers-0.21.1:\n","      Successfully uninstalled tokenizers-0.21.1\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.51.3\n","    Uninstalling transformers-4.51.3:\n","      Successfully uninstalled transformers-4.51.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.28.1 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 evaluate-0.4.3 fsspec-2025.3.0 multiprocess-0.70.16 tokenizers-0.13.3 transformers-4.28.1 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","from transformers import BertTokenizer, BertModel, AdamW, BertConfig\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n","from sklearn.utils import resample\n","import copy\n","import spacy\n","from collections import Counter\n","\n","from transformers.utils import logging\n","logging.set_verbosity_error()\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"WfVbN7LLVqaO","executionInfo":{"status":"ok","timestamp":1747021546932,"user_tz":240,"elapsed":14359,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"6ef793d0-efbd-4469-a069-919deb433807"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["model_name = \"bert-base-cased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","nlp = spacy.load(\"en_core_web_sm\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223,"referenced_widgets":["4122ff908c454fc986d67229873fb413","c1fd900a57fb48878b74f8f23555ad00","2909637fbfa540c7af2242375284d844","f2b37271e06640608bf1117b34467846","75c35b84e88f4cbca11b1ffe7eee95e0","3c97b91b19a24f00bb6fce68e76cb693","102b9cd32d084e38942cafaf4dde38c1","e56d4d6460304985a7b6ce6eca8fbb7a","b286dadd95ef4580b28d20e93e23bd35","6fa1c9fbb7ed433298023b091641b06a","c980375cedd04adcac343bbf9f427d29","267e95c491e04a55bf4d8861db3f34e7","c9eb311d27f1462eb0e27ed312814f1d","a838b1a533204c6789f1a6f5df32e1a0","d4312253bf24492a94e585cd471f1242","fe414a5faa454de2a438e36e478fe2c0","d4dd4c70bda048e8a34121310ea69890","8e0578c4fa5f478db8efe52ddde072da","4aca6ebe2f1a41fdac7f0589e53baa6f","381004140fbd4d21af36730a5a5d4ecf","4df0650775024204bef23204b22accd1","5e2b84aa7b43412c9f5c1460356b93e6","3d41a935d52645b0ae57be9c396a8631","96d8932fed284510be9c0c0bef8fe3f3","bc57b371edb14413a599c3ee2568b17d","96309ac6b169433eb2e812bfefb65d3f","31c6b3f8481e410d8df2df2de87e61c3","3a68742c903446e981ac0e7b6152c245","8086b9bb12da4a6f8ac47dcb0379a613","e84e918605ec43bebacf86983a85a534","797ba0f83d2542d4a72a35866cf29705","d1f4a7ad075b4db6a80d407c1a88db96","8a090b9d9a984a07859111c83ae41a70"]},"id":"mkmZwY020KI0","executionInfo":{"status":"ok","timestamp":1747021550427,"user_tz":240,"elapsed":3492,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"26084a7e-c9eb-4890-afd3-1e23f2167fda"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4122ff908c454fc986d67229873fb413"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"267e95c491e04a55bf4d8861db3f34e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d41a935d52645b0ae57be9c396a8631"}},"metadata":{}}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"fnozgUEyWcUK","executionInfo":{"status":"ok","timestamp":1747021550457,"user_tz":240,"elapsed":29,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"5186c122-1fe7-4cec-9d11-67c9b5ca0196"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/wac_project/QA_v2/df_sentences_context.xlsx')\n","df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)\n","df[\"context\"] = df[\"context\"].fillna(\"\").astype(str)\n","\n","label_list = list(df['label'].unique())\n","\n","label2id = {'Evidence': 0,\n","            'Organizational Framework': 1,\n","            'Reasoning': 2,\n","            'Rhetorical Structure - Focus': 3,\n","            'Rhetorical Structure - Progression': 4,\n","            'Thesis': 5,\n","            'normal_text': 6,\n","            'grouped': 7}\n","\n","id2label = {i: label for label, i in label2id.items()}\n","\n","evidence = 'Evidence'\n","org_framework ='Organizational Framework'\n","reasoning = 'Reasoning'\n","focus = 'Rhetorical Structure - Focus'\n","progression = 'Rhetorical Structure - Progression'\n","thesis = 'Thesis'\n","normal_text = 'normal_text'\n","grouped = 'grouped'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"7HjAhWDtom0Z","executionInfo":{"status":"ok","timestamp":1747021556931,"user_tz":240,"elapsed":6472,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"5fa36797-d4ed-4e54-d146-af524c1ed797"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["def convert_df_to_binary_on_column(df, col, val):\n","  df_temp = df.copy(deep=True)\n","  df_temp[col] = df_temp[col].apply(lambda x: 1 if x != val else 0)\n","  return df_temp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"NpLQO9zYqgUM","executionInfo":{"status":"ok","timestamp":1747021556951,"user_tz":240,"elapsed":18,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"57c9ac79-d15d-403b-f29a-0fef399a2fa0"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["def split_data(df, train_size=0.7, test_size=0.15, eval_size=0.15, strategy=None, random_state=42):\n","  if strategy == 'id':\n","    train_id, temp_id = train_test_split(\n","        df['file_id'].unique(),\n","        train_size=train_size,\n","        random_state=random_state\n","        )\n","\n","    val_id, test_id = train_test_split(\n","        temp_id,\n","        test_size=np.round(test_size / (1 - train_size), 1),\n","        random_state=random_state\n","    )\n","\n","    train_df = df[df['file_id'].isin(train_id)].copy(deep=True)\n","    val_df = df[df['file_id'].isin(val_id)].copy(deep=True)\n","    test_df = df[df['file_id'].isin(test_id)].copy(deep=True)\n","\n","    return train_df, test_df, val_df\n","\n","  else:\n","    train_df, temp_df = train_test_split(\n","        df,\n","        test_size=1-train_size,\n","        random_state=random_state\n","        )\n","    val_df, test_df = train_test_split(\n","        temp_df,\n","        test_size=np.round(test_size / (1 - train_size), 1),\n","        random_state=random_state\n","    )\n","    return train_df.copy(deep=True), test_df.copy(deep=True), val_df.copy(deep=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"lrz_LdLZ4698","executionInfo":{"status":"ok","timestamp":1747021556989,"user_tz":240,"elapsed":36,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"b1f77121-801a-4c66-fd2c-eb0da875222a"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["def balance_df(df):\n","  assert set(df['y'].unique()).issubset({0, 1})\n","  target_ratio = 0.15\n","  ones_df = df[df['y'] == 1]\n","  zeros_df = df[df['y'] == 0]\n","  n_ones = len(ones_df)\n","  total_desired = int(n_ones / target_ratio)\n","  n_zeros_needed = total_desired - n_ones\n","  sampled_zeros_df = zeros_df.sample(n=n_zeros_needed, random_state=42) # Downsample 0s\n","  balanced_df = pd.concat([ones_df, sampled_zeros_df]).sample(frac=1, random_state=42).reset_index(drop=True) # Combine\n","  return balanced_df\n","\n","def perfect_balancing_downsampling(df, y='label', label=None, random_state=42):\n","  df_value_counts = df[y].value_counts()\n","  if label is not None:\n","     min_count = df_value_counts.loc[label]\n","  else:\n","    min_count = min(df_value_counts)\n","\n","  labels = df[y].unique()\n","  df_list = []\n","  for label in labels:\n","    df_label = df[df[y] == label]\n","    # n = min_count if min_count <= df_value_counts[label] else df_value_counts[label]\n","    df_label = df_label.sample(n=min_count, replace=True, random_state=random_state)\n","    df_list.append(df_label)\n","  df_final = pd.concat(df_list).reset_index(drop=True).copy(deep=True)\n","  return df_final\n","\n","def add_pos_tags(text):\n","    doc = nlp(text)\n","    return \" \".join([f\"{token.text}/{token.pos_}\" for token in doc])\n","\n","def replace_with_pos_tags(text):\n","    doc = nlp(text)\n","    return \" \".join([f\"{token.pos_}\" for token in doc])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"3rm8X0s1myfb","executionInfo":{"status":"ok","timestamp":1747021557031,"user_tz":240,"elapsed":31,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"f48afa0c-0eea-4589-88e3-8ac5e9c65bf6"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["def encode_df(df_subset, encode_pair=False):\n","    df_subset = df_subset.copy()\n","    df_subset[\"text\"] = df_subset[\"text\"].fillna(\"\").astype(str)\n","    df_subset[\"context\"] = df_subset[\"context\"].fillna(\"\").astype(str)\n","\n","    if encode_pair:\n","        ret = tokenizer(\n","            list(df_subset[\"text\"]),\n","            list(df_subset[\"context\"]),\n","            padding=True,\n","            truncation=True,\n","            max_length=512,\n","            return_tensors=\"pt\",\n","            return_overflowing_tokens=False)\n","    else:\n","        ret = tokenizer(\n","            list(df_subset[\"text\"]),\n","            padding=True,\n","            truncation=True,\n","            max_length=512,\n","            return_tensors=\"pt\",\n","            return_overflowing_tokens=False)\n","\n","    return ret"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"8VkgIji8DINk","executionInfo":{"status":"ok","timestamp":1747021557040,"user_tz":240,"elapsed":7,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"15d0aea9-5a88-471d-cf5f-10b3608851f8"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["add_pos = False\n","encode_pair = False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"0HxzVlYNXZb8","executionInfo":{"status":"ok","timestamp":1747021557056,"user_tz":240,"elapsed":14,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"7afa940d-89e3-4862-b489-f3b914e2f5e3"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["if add_pos:\n","  print('Add POS Tags - ', add_pos)\n","  df['text'] = df['text'].apply(replace_with_pos_tags)\n","  df['context'] = df['context'].apply(add_pos_tags)\n","\n","train_df, test_df, val_df = split_data(df, train_size=0.7, test_size=0.15, eval_size=0.15, strategy='id', random_state=42)\n","\n","# train_df = perfect_balancing_downsampling(train_df)\n","\n","# train_df['label'] = train_df['label'].map(label2id)\n","# test_df['label'] = test_df['label'].map(label2id)\n","# val_df['label'] = val_df['label'].map(label2id)\n","\n","# print('Sentence Pair Encoding - ', encode_pair)\n","\n","# train_encodings = encode_df(train_df, encode_pair)\n","# val_encodings = encode_df(val_df, encode_pair)\n","# test_encodings = encode_df(test_df, encode_pair)\n","\n","# train_labels = torch.tensor(train_df[\"label\"].astype(int).values).to(device)\n","# val_labels = torch.tensor(val_df[\"label\"].astype(int).values).to(device)\n","# test_labels = torch.tensor(test_df[\"label\"].astype(int).values).to(device)\n","\n","# train_inputs = {k: v.to(device) for k, v in train_encodings.items()}\n","# val_inputs = {k: v.to(device) for k, v in val_encodings.items()}\n","# test_inputs = {k: v.to(device) for k, v in test_encodings.items()}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"d3hlz-UoWg43","executionInfo":{"status":"ok","timestamp":1747021557091,"user_tz":240,"elapsed":33,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"92098ec6-18be-4f20-d5b8-30c9595c9896"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["class BertMultiClassClassifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.bert = BertModel.from_pretrained(model_name)\n","        self.dropout = nn.Dropout(0.3)\n","        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        cls_output = outputs.pooler_output\n","        x = self.dropout(cls_output)\n","        return self.classifier(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"46U7dJp8Wl58","executionInfo":{"status":"ok","timestamp":1747021557119,"user_tz":240,"elapsed":26,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"e036139d-d583-4ac8-d10f-a633528dc862"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["import os\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"kL5fO3FkGYzN","executionInfo":{"status":"ok","timestamp":1747021557144,"user_tz":240,"elapsed":23,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"bd6cda07-04d3-4e53-8b78-2d2eb6bc4226"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","num_labels = [0, 1, 2, 3, 4, 5, 6] # train_df['label'].unique()\n","num_labels.sort()\n","\n","class_weights = compute_class_weight(class_weight='balanced', classes=np.array(label_list), y=train_df['label'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"JCyQfkV3uxvK","executionInfo":{"status":"ok","timestamp":1747021557192,"user_tz":240,"elapsed":46,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"9ac31c3f-6a93-464f-fa20-e0c01ef56496"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["# **Basic Methods**"],"metadata":{"id":"er82dyvKq_HE"}},{"cell_type":"code","source":["# num_labels = list(label2id.values())\n","# string_labels = [id2label[i] for i in num_labels]\n","# num_classes = len(label2id)\n","\n","def train_model(model, train_inputs, train_labels, val_inputs, val_labels, batch_size=32, weighted_loss=False, criterion=None):\n","  optimizer = AdamW(model.parameters(), lr=2e-5)\n","\n","  if criterion is None:\n","    if weighted_loss:\n","      criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(class_weights).float().to(device))\n","    else:\n","      criterion = nn.CrossEntropyLoss()\n","\n","  epochs = 50\n","  patience = 3\n","  best_val_loss = float(\"inf\")\n","  patience_counter = 0\n","  best_model_state = None\n","\n","  model.train()\n","\n","  for epoch in range(epochs):\n","      total_train_loss = 0\n","      model.train()\n","\n","      for i in range(0, len(train_labels), batch_size):\n","          input_batch = {k: v[i:i+batch_size] for k, v in train_inputs.items()}\n","          label_batch = train_labels[i:i+batch_size]\n","\n","          optimizer.zero_grad()\n","          logits = model(**input_batch)\n","          loss = criterion(logits, label_batch)\n","          loss.backward()\n","          optimizer.step()\n","\n","          total_train_loss += loss.item()\n","\n","      avg_train_loss = total_train_loss / (len(train_labels) // batch_size + 1)\n","\n","      torch.cuda.empty_cache()\n","      torch.cuda.ipc_collect()\n","\n","      model.eval()\n","      val_loss = 0\n","\n","      with torch.no_grad():\n","          for i in range(0, len(val_labels), batch_size):\n","              batch = {k: v[i:i+batch_size] for k, v in val_inputs.items()}\n","              label_batch = val_labels[i:i+batch_size]\n","\n","              logits = model(**batch)\n","              loss = criterion(logits, label_batch)\n","\n","              val_loss += loss.item()\n","\n","      avg_val_loss = val_loss / (len(val_labels) // batch_size + 1)\n","      print(f\"Epoch {epoch+1}/{epochs} — Train Loss: {avg_train_loss:.4f} — Val Loss: {avg_val_loss:.4f}\")\n","\n","\n","      if val_loss < best_val_loss:\n","          best_val_loss = val_loss\n","          patience_counter = 0\n","          best_model_state = copy.deepcopy(model.state_dict())\n","      else:\n","          patience_counter += 1\n","          if patience_counter >= patience:\n","              print(\"Early stopping triggered.\")\n","              break\n","\n","      torch.cuda.empty_cache()\n","      torch.cuda.ipc_collect()\n","\n","  if best_model_state is not None:\n","      model.load_state_dict(best_model_state)\n","\n","  return model, best_val_loss\n","\n","def test_model(model, test_inputs, test_labels, batch_size=32):\n","  model.eval()\n","  all_preds = []\n","  all_true = []\n","\n","  with torch.no_grad():\n","      for i in range(0, len(test_labels), batch_size):\n","          batch_inputs = {k: v[i:i+batch_size] for k, v in test_inputs.items()}\n","          label_batch = test_labels[i:i+batch_size]\n","\n","          logits = model(**batch_inputs)#.logits\n","          preds = torch.argmax(logits, dim=1)\n","\n","          all_preds.extend(preds.cpu().numpy())\n","          all_true.extend(label_batch.cpu().numpy())\n","\n","  torch.cuda.empty_cache()\n","  torch.cuda.ipc_collect()\n","\n","  y_true = np.array(all_true)\n","  y_pred = np.array(all_preds)\n","\n","  performance_metrics = np.asarray(precision_recall_fscore_support(y_true, y_pred, zero_division=0)) # , labels=num_labels\n","\n","  return performance_metrics.T, y_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"4ARI1H6-GIDc","executionInfo":{"status":"ok","timestamp":1747021557230,"user_tz":240,"elapsed":36,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"693815c9-6e38-46fa-b30f-27d5199369f2"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["# **Ensemble Methods**"],"metadata":{"id":"U8wuTqbUqzxA"}},{"cell_type":"code","source":["def train_ensemble_model(models, train_inputs_list, train_labels_list, val_input, val_label, weighted_loss=False):\n","  trained_models = []\n","  for model, train_inputs, train_labels in zip(models, train_inputs_list, train_labels_list):\n","    trained_model, best_val_loss = train_model(model, train_inputs, train_labels, val_input, val_label, weighted_loss=weighted_loss)\n","    trained_models.append(trained_model)\n","    print()\n","\n","  return trained_models\n","\n","def test_ensemble_model(models, test_inputs, test_labels, batch_size=32, strategy='hard vote'):\n","    def hard_voting(tensors):\n","        np_tensors = [t.numpy() for t in tensors]\n","        stacked = np.stack(np_tensors)\n","        result = []\n","        for i in range(stacked.shape[1]):\n","            col = stacked[:, i]\n","            count = Counter(col)\n","            max_freq = max(count.values())\n","            most_common_values = [val for val, freq in count.items() if freq == max_freq]\n","            result.append(min(most_common_values))\n","        return torch.tensor(result)\n","\n","    def soft_voting(probs_list):\n","        stacked = torch.stack(probs_list)\n","        avg_probs = stacked.mean(dim=0)\n","        return torch.argmax(avg_probs, dim=1)\n","\n","    y_true = test_labels.cpu().numpy()\n","    model_predictions = []\n","\n","    for model in models:\n","        model.eval()\n","        all_preds = []\n","\n","        with torch.no_grad():\n","            for i in range(0, len(test_labels), batch_size):\n","                batch_inputs = {k: v[i:i+batch_size] for k, v in test_inputs.items()}\n","                logits = model(**batch_inputs)\n","\n","                if strategy == 'hard vote':\n","                    preds = torch.argmax(logits, dim=1)\n","                    all_preds.extend(preds.cpu().numpy())\n","                elif strategy == 'soft vote':\n","                    probs = F.softmax(logits, dim=1)\n","                    all_preds.append(probs.cpu())\n","                else:\n","                    raise ValueError(f\"Unknown strategy: {strategy}\")\n","\n","        if strategy == 'hard vote':\n","            model_predictions.append(torch.tensor(all_preds))\n","        elif strategy == 'soft vote':\n","            model_predictions.append(torch.cat(all_preds, dim=0))\n","\n","        torch.cuda.empty_cache()\n","        torch.cuda.ipc_collect()\n","\n","    if strategy == 'hard vote':\n","        final_predictions = hard_voting(model_predictions).numpy()\n","    else:\n","        final_predictions = soft_voting(model_predictions).cpu().numpy()\n","\n","    performance_metrics = np.asarray(\n","        precision_recall_fscore_support(y_true, final_predictions, labels=num_labels, zero_division=0)\n","    )\n","\n","    return performance_metrics.T, final_predictions, y_true\n","\n","def test_hierarchical_classification_ensemble(models, test_inputs, test_labels, c1_reverse_label_map, c2_reverse_label_map, c3_reverse_label_map):\n","  batch_size = 1\n","  classifier_1, classifier_2, classifier_3 = models\n","  predictions = []\n","  for i in range(0, len(test_labels), batch_size):\n","      batch_inputs = {k: v[i:i+batch_size] for k, v in test_inputs.items()}\n","      label_batch = test_labels[i:i+batch_size]\n","\n","      logits = classifier_1(**batch_inputs)\n","      c1_pred = int(torch.argmax(logits))\n","      if c1_pred == 0:\n","          predictions.append(c1_reverse_label_map[c1_pred])\n","      else:\n","          logits = classifier_2(**batch_inputs)\n","          c2_pred = int(torch.argmax(logits))\n","          if c2_pred != 2:\n","            predictions.append(c2_reverse_label_map[c2_pred])\n","          else:\n","            logits = classifier_3(**batch_inputs)\n","            c3_pred = int(torch.argmax(logits))\n","            predictions.append(c3_reverse_label_map[c3_pred])\n","\n","  y_true = test_labels.cpu().numpy()\n","  y_pred = np.array(predictions)\n","\n","  performance_metrics = np.asarray(precision_recall_fscore_support(y_true, y_pred, zero_division=0))\n","\n","  return performance_metrics.T, y_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"2xA4nzQKmqlF","executionInfo":{"status":"ok","timestamp":1747021557261,"user_tz":240,"elapsed":29,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"12dd206d-62ad-4f74-9e7a-bc19bda8ca7d"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["# model = BertMultiClassClassifier(num_classes).to(device)\n","# test_ensemble_model([model]*3, test_inputs, test_labels, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"MWKtUiJnePoi","executionInfo":{"status":"ok","timestamp":1747021557293,"user_tz":240,"elapsed":9,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"fac67117-5d3d-4d31-92a6-cfaef563fd98"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["def create_c1_df(df, y='label'):\n","  new_df = df.copy(deep=True)\n","  new_df[y] = new_df[y].apply(lambda x: normal_text if x == normal_text else grouped)\n","  return new_df\n","\n","def create_c2_df(df, y='label'):\n","  new_df = df.copy(deep=True)\n","  new_df = new_df[new_df[y] != normal_text ]\n","  new_df[y] = new_df[y].apply(lambda x: x if x in (reasoning, evidence) else grouped)\n","  return new_df\n","\n","def create_c3_df(df, y='label'):\n","  new_df = df.copy(deep=True)\n","  new_df = new_df[new_df[y].isin((focus, thesis, progression, org_framework))]\n","  return new_df\n","\n","def create_voting_system_dfs(df, y='label'):\n","  label_counts = df[y].value_counts().to_dict()\n","  min_class_size = min(label_counts.values())\n","  all_labels = label_counts.keys()\n","\n","  df1 = pd.concat([ resample(df[df[y] == label], n_samples=150, random_state=42) for label in all_labels ]).copy(deep=True)\n","\n","  mild_targets = {\n","      normal_text : 1000,\n","      reasoning: 1368,\n","      evidence: 1227,\n","      focus: 500,\n","      thesis: 300,\n","      progression: 300,\n","      org_framework: 300\n","  }\n","\n","  df2 = pd.concat([\n","      resample(\n","          df[df[y] == label],\n","          n_samples=count,\n","          random_state=43,\n","          replace=True\n","      )\n","      for label, count in mild_targets.items()\n","      # if label in df[y].unique() and len(df[df[y] == label]) > 0\n","  ]).copy(deep=True)\n","\n","  df3 = [df[df[y] == 'normal_text']]\n","  for label in all_labels:\n","      if label != 'normal_text':\n","          original = df[df[y] == label]\n","          n = max(1, int(0.7 * len(original)))  # avoid 0\n","          df3.append(resample(original, n_samples=n, random_state=44))\n","  df3 = pd.concat(df3).copy(deep=True)\n","\n","  df_overminor = []\n","  if normal_text in df[y].unique():\n","      norm_count = min(2000, len(df[df[y] == normal_text]))\n","      df_overminor.append(resample(df[df[y] == normal_text], n_samples=norm_count, random_state=45))\n","\n","  for label in [reasoning, evidence, focus]:\n","      if label in df[y].unique():\n","          df_overminor.append(df[df[y] == label])\n","\n","  for label in [thesis, progression, org_framework]:\n","      if label in df[y].unique():\n","          class_df = df[df[y] == label]\n","          n = 3 * len(class_df)\n","          if n > 0:\n","              df_overminor.append(resample(class_df, replace=True, n_samples=n, random_state=46))\n","\n","  df4 = pd.concat(df_overminor).copy(deep=True)\n","\n","  df5 = resample(df, n_samples=len(df), replace=True, stratify=df[y], random_state=49).copy(deep=True)\n","\n","  return df1, df2, df3, df4, df5\n","\n","def create_c_encodings(df, create_c_df, c_label_map, y='label'):\n","  new_df = create_c_df(df)\n","  new_df.loc[:, y] = new_df[y].map(label2id)\n","  new_df.loc[:, y] = new_df[y].map(c_label_map)\n","  encodings = encode_df(new_df)\n","  labels = torch.tensor(new_df[y].astype(int).values).to(device)\n","  inputs = {k: v.to(device) for k, v in encodings.items()}\n","  return inputs, labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"5Cfnsl5yrxLT","executionInfo":{"status":"ok","timestamp":1747021557304,"user_tz":240,"elapsed":9,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"825785bd-c733-4598-d33c-7839f66bd335"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["# train_df, test_df, val_df = split_data(df, train_size=0.7, test_size=0.15, eval_size=0.15, strategy='id', random_state=42)\n","\n","# c1_label_map = {6:0, 7:1}\n","# c1_reverse_label_map = {i: label for label, i in c1_label_map.items()}\n","\n","# c1_train_inputs, c1_train_labels = create_c_encodings(train_df, create_c1_df, c1_label_map)\n","# c1_val_inputs, c1_val_labels = create_c_encodings(val_df, create_c1_df, c1_label_map)\n","# c1_test_inputs, c1_test_labels = create_c_encodings(test_df, create_c1_df, c1_label_map)\n","\n","# c1_num_classes = len(c1_label_map)\n","# cl_classifier = BertMultiClassClassifier(len(c1_num_classes)).to(device)\n","# cl_classifier_trained, c1_best_val_loss = train_model(cl_classifier, c1_train_inputs, c1_train_labels, c1_val_inputs, c1_val_labels, batch_size=32, weighted_loss=False)\n","\n","# performnce_matrix, y_preds = test_model(cl_classifier_trained, c1_test_inputs, c1_test_labels, batch_size=32)\n","# print(pd.DataFrame(performnce_matrix, columns=['precision', 'recall', 'F1', 'support']).rename(index=c1_reverse_label_map).rename(index=id2label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"pUTO8IM-t-UW","executionInfo":{"status":"ok","timestamp":1747021557315,"user_tz":240,"elapsed":8,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"4b1228e4-38f7-4d90-d3f1-74fc55590805"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["# y = 'label'\n","# batch_size = 32\n","# n_run_metrics = []\n","# for run in range(3):\n","#   print(f'Run {run+1}')\n","\n","#   # Classifier 1\n","#   c1_label_map = {6:0, 7:1}\n","#   c1_reverse_label_map = {i: label for label, i in c1_label_map.items()}\n","\n","#   c1_train_inputs, c1_train_labels = create_c_encodings(train_df, create_c1_df, c1_label_map)\n","#   c1_val_inputs, c1_val_labels = create_c_encodings(val_df, create_c1_df, c1_label_map)\n","\n","#   c1_num_classes = len(c1_label_map)\n","#   cl_classifier = BertMultiClassClassifier(c1_num_classes).to(device)\n","#   cl_classifier_trained, c1_best_val_loss = train_model(cl_classifier, c1_train_inputs, c1_train_labels, c1_val_inputs, c1_val_labels, batch_size=batch_size, weighted_loss=False)\n","\n","#   print()\n","#   # Classifier 2\n","#   c2_label_map = {2:0, 0:1, 7:2}\n","#   c2_reverse_label_map = {i: label for label, i in c2_label_map.items()}\n","\n","#   c2_train_inputs, c2_train_labels = create_c_encodings(train_df, create_c2_df, c2_label_map)\n","#   c2_val_inputs, c2_val_labels = create_c_encodings(val_df, create_c2_df, c2_label_map)\n","\n","#   c2_num_classes = len(c2_label_map)\n","#   c2_classifier = BertMultiClassClassifier(c2_num_classes).to(device)\n","#   c2_classifier_trained, c2_best_val_loss = train_model(c2_classifier, c2_train_inputs, c2_train_labels, c2_val_inputs, c2_val_labels, batch_size=batch_size, weighted_loss=False)\n","\n","#   print()\n","#   # Classifier 3\n","#   c3_label_map = {3:0, 5:1, 4:2, 1:3}\n","#   c3_reverse_label_map = {i: label for label, i in c3_label_map.items()}\n","\n","#   c3_train_inputs, c3_train_labels = create_c_encodings(train_df, create_c3_df, c3_label_map)\n","#   c3_val_inputs, c3_val_labels = create_c_encodings(val_df, create_c3_df, c3_label_map)\n","\n","#   c3_num_classes = len(c3_label_map)\n","#   c3_classifier = BertMultiClassClassifier(c3_num_classes).to(device)\n","#   c3_classifier_trained, c3_best_val_loss = train_model(c3_classifier, c3_train_inputs, c3_train_labels, c3_val_inputs, c3_val_labels, batch_size=batch_size, weighted_loss=False)\n","\n","#   trained_classifier = [cl_classifier_trained, c2_classifier_trained, c3_classifier_trained]\n","#   current_run_metrics, test_predictions = test_hierarchical_classification_ensemble(trained_classifier, test_inputs, test_labels, c1_reverse_label_map, c2_reverse_label_map, c3_reverse_label_map)\n","#   n_run_metrics.append(current_run_metrics)\n","#   print(pd.DataFrame(current_run_metrics, columns=['precision', 'recall', 'F1', 'support']).rename(index=id2label))\n","\n","# avg_n_run_metrics = pd.DataFrame(np.mean(np.asarray(n_run_metrics), axis=0), columns=['precision','recall','F1','support']) #  index=label_mapping\n","# print('\\nAverge Metrics')\n","# print(avg_n_run_metrics.rename(index=id2label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"JuayUzYVwnHs","executionInfo":{"status":"ok","timestamp":1747021557357,"user_tz":240,"elapsed":38,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"outputId":"f2e25df9-3d10-4ac6-deb7-98005ee50608"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["# batch_size = 32\n","# n_run_metrics = []\n","# for run in range(3):\n","#   print(f'Run {run+1}')\n","\n","#   custom_train_df = train_df.copy(deep=True)\n","#   custom_val_df = val_df.copy(deep=True)\n","#   custom_test_df = test_df.copy(deep=True)\n","\n","#   label_remap = {1:0, 3:1, 4:2, 5:3}\n","#   reverse_label_remap = {i: label for label, i in label_remap.items()}\n","#   label_mapping = { id2label[j]:i for i, j in reverse_label_remap.items()}\n","#   print(\"Label remap:\", label_remap)\n","\n","#   custom_train_df = custom_train_df[custom_train_df['label'].isin([focus, thesis, progression, org_framework])]\n","#   # custom_train_df.loc[:, 'label'] = custom_train_df['label'].apply(lambda x: x if x in (reasoning, evidence) else grouped)\n","#   custom_train_df.loc[:, 'label'] = custom_train_df['label'].map(label2id)\n","#   custom_train_df.loc[:, 'label'] = custom_train_df['label'].map(label_remap)\n","#   train_encodings = encode_df(custom_train_df, encode_pair)\n","#   train_labels = torch.tensor(custom_train_df[\"label\"].astype(int).values).to(device)\n","#   train_inputs = {k: v.to(device) for k, v in train_encodings.items()}\n","\n","#   custom_val_df = custom_val_df[custom_val_df['label'].isin([focus, thesis, progression, org_framework])]\n","#   # custom_val_df.loc[:, 'label'] = custom_val_df['label'].apply(lambda x: x if x in (reasoning, evidence) else grouped)\n","#   custom_val_df.loc[:, 'label'] = custom_val_df['label'].map(label2id)\n","#   custom_val_df.loc[:, 'label'] = custom_val_df['label'].map(label_remap)\n","#   val_encodings = encode_df(custom_val_df, encode_pair)\n","#   val_labels = torch.tensor(custom_val_df[\"label\"].astype(int).values).to(device)\n","#   val_inputs = {k: v.to(device) for k, v in val_encodings.items()}\n","\n","#   custom_test_df = custom_test_df[custom_test_df['label'].isin([focus, thesis, progression, org_framework])]\n","#   # custom_test_df.loc[:, 'label'] = custom_test_df['label'].apply(lambda x: x if x in (reasoning, evidence) else grouped)\n","#   custom_test_df.loc[:, 'label'] = custom_test_df['label'].map(label2id)\n","#   custom_test_df.loc[:, 'label'] = custom_test_df['label'].map(label_remap)\n","#   test_encodings = encode_df(custom_test_df, encode_pair)\n","#   test_labels = torch.tensor(custom_test_df[\"label\"].astype(int).values).to(device)\n","#   test_inputs = {k: v.to(device) for k, v in test_encodings.items()}\n","\n","#   num_classes = len(label_remap)\n","#   model = BertMultiClassClassifier(num_classes).to(device)\n","\n","#   trained_model, best_val_loss = train_model(model, train_inputs, train_labels, val_inputs, val_labels, batch_size=batch_size, weighted_loss=False)\n","\n","#   current_run_metrics, _ = test_model(trained_model, test_inputs, test_labels, batch_size=batch_size)\n","#   n_run_metrics.append(current_run_metrics)\n","#   print('Test Results:')\n","#   print(pd.DataFrame(current_run_metrics, columns=['precision', 'recall', 'F1', 'support'], index=label_mapping))\n","\n","# avg_n_run_metrics = pd.DataFrame(np.mean(np.asarray(n_run_metrics), axis=0), columns=['precision','recall','F1','support'], index=label_mapping)\n","# print('\\nAverge Metrics')\n","# print(avg_n_run_metrics)"],"metadata":{"id":"UhQuizOt5Uhb","executionInfo":{"status":"ok","timestamp":1747021557401,"user_tz":240,"elapsed":42,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"89fc6926-9008-4659-d6dd-ddccc29921c6"},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["n_run_metrics = []\n","\n","train_df, test_df, val_df = split_data(df, train_size=0.7, test_size=0.15, eval_size=0.15, strategy='id', random_state=42)\n","\n","test_df['label'] = test_df['label'].map(label2id)\n","val_df['label'] = val_df['label'].map(label2id)\n","\n","val_encodings = encode_df(val_df, encode_pair)\n","test_encodings = encode_df(test_df, encode_pair)\n","\n","val_labels = torch.tensor(val_df[\"label\"].astype(int).values).to(device)\n","test_labels = torch.tensor(test_df[\"label\"].astype(int).values).to(device)\n","\n","val_inputs = {k: v.to(device) for k, v in val_encodings.items()}\n","test_inputs = {k: v.to(device) for k, v in test_encodings.items()}\n","\n","dfs = create_voting_system_dfs(train_df, y='label')\n","\n","for run in range(1):\n","  print(f'Run {run+1}')\n","\n","  num_classes = len(num_labels)\n","\n","  train_inputs_list, train_labels_list = [], []\n","  val_inputs_list, val_labels_list = [], []\n","  models = []\n","  for df in dfs:\n","    df['label'] = df['label'].map(label2id)\n","    aug_encodings = encode_df(df, encode_pair)\n","\n","    train_labels = torch.tensor(df[\"label\"].astype(int).values).to(device)\n","    train_inputs = {k: v.to(device) for k, v in aug_encodings.items()}\n","\n","    train_inputs_list.append(train_inputs)\n","    train_labels_list.append(train_labels)\n","    models.append(BertMultiClassClassifier(num_classes).to(device))\n","\n","  model = BertMultiClassClassifier(num_classes).to(device)\n","  trained_models = train_ensemble_model(models, train_inputs_list, train_labels_list, val_inputs, val_labels)\n","\n","  print('Ensemble Testing')\n","  current_run_metrics, _, _ = test_ensemble_model(trained_models, test_inputs, test_labels, batch_size=32, strategy='hard vote')\n","\n","  print('Hard Vote Evaluation Results:')\n","  print(pd.DataFrame(current_run_metrics, columns=['precision', 'recall', 'F1', 'support']).rename(index=id2label))\n","\n","  current_run_metrics, _, _ = test_ensemble_model(trained_models, test_inputs, test_labels, batch_size=32, strategy='soft vote')\n","\n","  print('Soft Vote Evaluation Results:')\n","  print(pd.DataFrame(current_run_metrics, columns=['precision', 'recall', 'F1', 'support']).rename(index=id2label))\n","\n","# avg_n_run_metrics = pd.DataFrame(np.mean(np.asarray(n_run_metrics), axis=0), columns=['precision','recall','F1','support'], index=string_labels)\n","# print('\\nAverge Metrics')\n","# print(avg_n_run_metrics)"],"metadata":{"id":"XNHoCGq0Wy-o","executionInfo":{"status":"error","timestamp":1747022883677,"user_tz":240,"elapsed":1326261,"user":{"displayName":"Rishabh Lingam","userId":"08776833142460081140"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["aa87df15d9f4408d8b7c6900bc45be5a","3f3f32d34ec549478bf5028b54e8f732","c60465af91674bae967c99a876ea0920","67111ab998474c8693df3d6ba4783de7","789f816ec93b4921886d07c4b86fc07a","e929dd7a529c41d2a78bdff2055f6bc8","3fbb1b0199e04aaf94ac1c2a0673c9dd","f8f786d9a3884b63b88821edb8fa58b4","753abd35ef4b41a99c4e3eb8f3aac5e8","144e957121fd4719808242e802e5b30e","1c41c6cea3cb4a988832711e8ff0087c"]},"outputId":"964c8de0-dd24-415d-832e-b2c7d2436e85"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Run 1\n"]},{"output_type":"stream","name":"stderr","text":["Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa87df15d9f4408d8b7c6900bc45be5a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/50 — Train Loss: 2.3344 — Val Loss: 1.5900\n","Epoch 2/50 — Train Loss: 2.1719 — Val Loss: 1.6297\n","Epoch 3/50 — Train Loss: 2.1194 — Val Loss: 1.6889\n","Epoch 4/50 — Train Loss: 2.1051 — Val Loss: 1.7280\n","Early stopping triggered.\n","\n","Epoch 1/50 — Train Loss: 1.2174 — Val Loss: 2.9743\n","Epoch 2/50 — Train Loss: 0.9010 — Val Loss: 2.1205\n","Epoch 3/50 — Train Loss: 0.9405 — Val Loss: 3.3795\n","Epoch 4/50 — Train Loss: 1.0331 — Val Loss: 3.9599\n","Epoch 5/50 — Train Loss: 1.7221 — Val Loss: 3.5315\n","Early stopping triggered.\n","\n","Epoch 1/50 — Train Loss: 0.6902 — Val Loss: 2.4986\n","Epoch 2/50 — Train Loss: 0.5596 — Val Loss: 2.8324\n","Epoch 3/50 — Train Loss: 0.4625 — Val Loss: 2.9708\n","Epoch 4/50 — Train Loss: 0.4014 — Val Loss: 2.5069\n","Early stopping triggered.\n","\n","Epoch 1/50 — Train Loss: 0.9905 — Val Loss: 3.5944\n","Epoch 2/50 — Train Loss: 0.6927 — Val Loss: 3.8028\n","Epoch 3/50 — Train Loss: 0.5617 — Val Loss: 4.6078\n","Epoch 4/50 — Train Loss: 0.8148 — Val Loss: 3.6035\n","Early stopping triggered.\n","\n","Epoch 1/50 — Train Loss: 1.2664 — Val Loss: 1.0191\n","Epoch 2/50 — Train Loss: 0.9649 — Val Loss: 1.0633\n","Epoch 3/50 — Train Loss: 0.6886 — Val Loss: 1.3057\n","Epoch 4/50 — Train Loss: 0.4185 — Val Loss: 1.5853\n","Early stopping triggered.\n","\n","Ensemble Testing\n","Hard Vote Evaluation Results:\n"]},{"output_type":"error","ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-bda57e69c6c3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hard Vote Evaluation Results:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_run_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'support'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mcurrent_run_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ensemble_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'soft vote'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    865\u001b[0m                     )\n\u001b[1;32m    866\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                     mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    868\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prep_ndarraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_on_sanitize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;31m#  np.asarray would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;31m# GH#21861 see test_constructor_list_of_lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"yCrQ01l1E_DF","outputId":"73a69563-f70b-4612-8b93-85d47c69871e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","mount_file_id":"1Gw4N8hu6zDdrZVmhukXz03rWQ6OUOJQc","authorship_tag":"ABX9TyOCidSap65ZXS2U/z6aaaNU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4122ff908c454fc986d67229873fb413":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1fd900a57fb48878b74f8f23555ad00","IPY_MODEL_2909637fbfa540c7af2242375284d844","IPY_MODEL_f2b37271e06640608bf1117b34467846"],"layout":"IPY_MODEL_75c35b84e88f4cbca11b1ffe7eee95e0"}},"c1fd900a57fb48878b74f8f23555ad00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c97b91b19a24f00bb6fce68e76cb693","placeholder":"​","style":"IPY_MODEL_102b9cd32d084e38942cafaf4dde38c1","value":"vocab.txt: 100%"}},"2909637fbfa540c7af2242375284d844":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e56d4d6460304985a7b6ce6eca8fbb7a","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b286dadd95ef4580b28d20e93e23bd35","value":213450}},"f2b37271e06640608bf1117b34467846":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fa1c9fbb7ed433298023b091641b06a","placeholder":"​","style":"IPY_MODEL_c980375cedd04adcac343bbf9f427d29","value":" 213k/213k [00:00&lt;00:00, 984kB/s]"}},"75c35b84e88f4cbca11b1ffe7eee95e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c97b91b19a24f00bb6fce68e76cb693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"102b9cd32d084e38942cafaf4dde38c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e56d4d6460304985a7b6ce6eca8fbb7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b286dadd95ef4580b28d20e93e23bd35":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fa1c9fbb7ed433298023b091641b06a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c980375cedd04adcac343bbf9f427d29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"267e95c491e04a55bf4d8861db3f34e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9eb311d27f1462eb0e27ed312814f1d","IPY_MODEL_a838b1a533204c6789f1a6f5df32e1a0","IPY_MODEL_d4312253bf24492a94e585cd471f1242"],"layout":"IPY_MODEL_fe414a5faa454de2a438e36e478fe2c0"}},"c9eb311d27f1462eb0e27ed312814f1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4dd4c70bda048e8a34121310ea69890","placeholder":"​","style":"IPY_MODEL_8e0578c4fa5f478db8efe52ddde072da","value":"tokenizer_config.json: 100%"}},"a838b1a533204c6789f1a6f5df32e1a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4aca6ebe2f1a41fdac7f0589e53baa6f","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_381004140fbd4d21af36730a5a5d4ecf","value":49}},"d4312253bf24492a94e585cd471f1242":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4df0650775024204bef23204b22accd1","placeholder":"​","style":"IPY_MODEL_5e2b84aa7b43412c9f5c1460356b93e6","value":" 49.0/49.0 [00:00&lt;00:00, 6.12kB/s]"}},"fe414a5faa454de2a438e36e478fe2c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4dd4c70bda048e8a34121310ea69890":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e0578c4fa5f478db8efe52ddde072da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4aca6ebe2f1a41fdac7f0589e53baa6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"381004140fbd4d21af36730a5a5d4ecf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4df0650775024204bef23204b22accd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e2b84aa7b43412c9f5c1460356b93e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d41a935d52645b0ae57be9c396a8631":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_96d8932fed284510be9c0c0bef8fe3f3","IPY_MODEL_bc57b371edb14413a599c3ee2568b17d","IPY_MODEL_96309ac6b169433eb2e812bfefb65d3f"],"layout":"IPY_MODEL_31c6b3f8481e410d8df2df2de87e61c3"}},"96d8932fed284510be9c0c0bef8fe3f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a68742c903446e981ac0e7b6152c245","placeholder":"​","style":"IPY_MODEL_8086b9bb12da4a6f8ac47dcb0379a613","value":"config.json: 100%"}},"bc57b371edb14413a599c3ee2568b17d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e84e918605ec43bebacf86983a85a534","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_797ba0f83d2542d4a72a35866cf29705","value":570}},"96309ac6b169433eb2e812bfefb65d3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1f4a7ad075b4db6a80d407c1a88db96","placeholder":"​","style":"IPY_MODEL_8a090b9d9a984a07859111c83ae41a70","value":" 570/570 [00:00&lt;00:00, 61.7kB/s]"}},"31c6b3f8481e410d8df2df2de87e61c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a68742c903446e981ac0e7b6152c245":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8086b9bb12da4a6f8ac47dcb0379a613":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e84e918605ec43bebacf86983a85a534":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"797ba0f83d2542d4a72a35866cf29705":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1f4a7ad075b4db6a80d407c1a88db96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a090b9d9a984a07859111c83ae41a70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa87df15d9f4408d8b7c6900bc45be5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f3f32d34ec549478bf5028b54e8f732","IPY_MODEL_c60465af91674bae967c99a876ea0920","IPY_MODEL_67111ab998474c8693df3d6ba4783de7"],"layout":"IPY_MODEL_789f816ec93b4921886d07c4b86fc07a"}},"3f3f32d34ec549478bf5028b54e8f732":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e929dd7a529c41d2a78bdff2055f6bc8","placeholder":"​","style":"IPY_MODEL_3fbb1b0199e04aaf94ac1c2a0673c9dd","value":"model.safetensors: 100%"}},"c60465af91674bae967c99a876ea0920":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8f786d9a3884b63b88821edb8fa58b4","max":435755784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_753abd35ef4b41a99c4e3eb8f3aac5e8","value":435755784}},"67111ab998474c8693df3d6ba4783de7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_144e957121fd4719808242e802e5b30e","placeholder":"​","style":"IPY_MODEL_1c41c6cea3cb4a988832711e8ff0087c","value":" 436M/436M [00:01&lt;00:00, 379MB/s]"}},"789f816ec93b4921886d07c4b86fc07a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e929dd7a529c41d2a78bdff2055f6bc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fbb1b0199e04aaf94ac1c2a0673c9dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8f786d9a3884b63b88821edb8fa58b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"753abd35ef4b41a99c4e3eb8f3aac5e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"144e957121fd4719808242e802e5b30e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c41c6cea3cb4a988832711e8ff0087c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}